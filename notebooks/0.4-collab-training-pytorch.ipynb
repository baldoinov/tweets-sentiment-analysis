{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Rl_hQrAB8nuiGAFCVvCvU3xpXzL07l1f","timestamp":1709081208906}],"gpuType":"L4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2987af016de046f19f9d55cce51dc3ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9ad3284136b64d2f8614e2a9a77ddf99","IPY_MODEL_035a820859614a95983f715f1d2ac3b3","IPY_MODEL_f0292a7bdc7f4248bae9a0c020df6194"],"layout":"IPY_MODEL_72c0c677febe48e58afd8cc05be8bb77"}},"9ad3284136b64d2f8614e2a9a77ddf99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d6abc5ad2f6488994caae1ea3a576fd","placeholder":"​","style":"IPY_MODEL_395c347cd2724a6a84718d118f192ada","value":"100%"}},"035a820859614a95983f715f1d2ac3b3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb3b5bf7042d43b792ea0b06fcfe5cac","max":24630,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3c03900bf68f4f24b109e0b5a36c976a","value":24630}},"f0292a7bdc7f4248bae9a0c020df6194":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cab01e20628a46dd9c51b6e669de727d","placeholder":"​","style":"IPY_MODEL_ebae17fa9af1446ba0f65ab56ecc1c82","value":" 24630/24630 [8:28:31&lt;00:00,  1.04s/it]"}},"72c0c677febe48e58afd8cc05be8bb77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d6abc5ad2f6488994caae1ea3a576fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"395c347cd2724a6a84718d118f192ada":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb3b5bf7042d43b792ea0b06fcfe5cac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c03900bf68f4f24b109e0b5a36c976a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cab01e20628a46dd9c51b6e669de727d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebae17fa9af1446ba0f65ab56ecc1c82":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["Vitor Domingos Baldoino dos Santos</br>\n","Universidade Presbiteriana Mackenzie</br>\n","Faculdade de Computação e Informática</br>\n","[vdbaldoino@gmail.com](mailto:vdbaldoino@gmail.com)</br>\n","\n","Dataset: [Portuguese Tweets for Sentiment Analysis](https://www.kaggle.com/datasets/augustop/portuguese-tweets-for-sentiment-analysis)\n","\n","Recursos para problemas que tive:\n","\n","- Não estava conseguindo implementar tudo que queria apenas utilizando a biblioteca da HuggingFace, então pensei em fazer o fine-tuning apenas com o PyTorch.\n","    - Para uma abordagem usando apenas o PyTorch, cheguei no link: [BERT Fine-Tuning Tutorial with PyTorch · Chris McCormick](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n","    - [Training with PyTorch](https://pytorch.org/tutorials/beginner/introyt/trainingyt.html)\n","    - [Hyperparameter tuning with Ray Tune](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html)\n","    - [Saving and loading a general checkpoint in PyTorch](https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html)\n","    - Para uma abordagem hibrída (HuggingFace + Training Loop do PyTorch), cheguei nessa documentação: [Fine-tune a pretrained model](https://huggingface.co/docs/transformers/training)\n","    - Publicação de exemplo: [análise de sentimentos em português utilizando Pytorch e Python](https://medium.com/data-hackers/an%C3%A1lise-de-sentimentos-em-portugu%C3%AAs-utilizando-pytorch-e-python-91a232165ec0)\n","- Para realizar a busca de hiperprâmetros no modelo achei a documentação abaixo, mas não consegui utilizar porque há um bug na integração com o `Ray Tune`.\n","    - [Hyperparameter Search with Transformers and Ray Tune](https://huggingface.co/blog/ray-tune)\n","- O link abaixxo é um notebook de exemplo para realizar a classificação de texto utilizando apenas as ferramentas da HuggingFace. Quase tudo nesse notebook foi tirado daqui. O segundo link é o tutorial de como monitorar o treinamento com o TensorBoard.\n","    - [Text Classification on GLUE using `Trainer`](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/text_classification.ipynb#scrollTo=8sgjdLKcIrJm)\n","    - [BERT Finetuning with Hugging Face and Training Visualizations with TensorBoard](https://medium.com/nlplanet/bert-finetuning-with-hugging-face-and-training-visualizations-with-tensorboard-46368a57fc97)\n","- Em algum momento percebi que o biblioteca da HuggingFace não calcula as métricas de performance do modelo no dataset de treino, impedindo a detecção de um possível overfitting. Para lidar com isso eu cheguei nos links abaixo:\n","    - [How to tweak `Trainer` to monitor other metrics on the training set](https://discuss.huggingface.co/t/metrics-for-training-set-in-trainer/2461/3)\n","    - [Batch and Epoch training metrics for transformers `Trainer`](https://stackoverflow.com/questions/78311534/batch-and-epoch-training-metrics-for-transformers-trainer/78311535#78311535)\n","\n","- [Performance tips for training](https://huggingface.co/docs/transformers/v4.18.0/en/performance)"],"metadata":{"id":"vU03CxahGR9y"}},{"cell_type":"markdown","source":["## Configurações"],"metadata":{"id":"1Ipvq20yQVtS"}},{"cell_type":"code","source":["%%shell\n","pip install -q transformers==4.39.3\n","pip install -q datasets==2.18.0\n","pip install -q torch==2.2.1\n","pip install -q ray[tune]==2.12.0\n","pip install -q scikit-learn==1.4.2\n","# pip install -q optuna\n","# pip install -q hyperopt"],"metadata":{"id":"Bug6zwn8Xlb2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714684527649,"user_tz":180,"elapsed":25714,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}},"outputId":"0f7d0adf-cd18-4c67-8ec9-1d9636e02c62"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["import os\n","import torch\n","import logging\n","import numpy as np\n","import pandas as pd\n","\n","from copy import deepcopy\n","\n","from datasets import load_from_disk\n","from datasets import DatasetDict\n","\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import accuracy_score\n","\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","\n","from tqdm.auto import tqdm\n","\n","from transformers import AutoModelForSequenceClassification\n","from transformers import AutoTokenizer\n","from transformers import DataCollatorWithPadding\n","from transformers import Trainer\n","from transformers import TrainingArguments\n","from transformers import get_scheduler"],"metadata":{"id":"blEwKx4jefw2","executionInfo":{"status":"ok","timestamp":1714684532827,"user_tz":180,"elapsed":5184,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/sentiment-analysis/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4wu55HRM3e-N","executionInfo":{"status":"ok","timestamp":1714684537426,"user_tz":180,"elapsed":4639,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}},"outputId":"75878831-c3ec-46e5-8b4d-7f5b632cd0a7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["SEED = 42\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","BATCH_SIZE = 128\n","NUM_LABELS = 3\n","MAX_LENGTH = 128\n","TASK = \"sentiment-analysis\"\n","MODEL_NAME = \"bertimbau\"\n","\n","ID2LABEL = {0: \"Neutro\", 1: \"Positivo\", 2: \"Negativo\"}\n","LABEL2ID = {\"Neutro\": 0, \"Positivo\": 1, \"Negativo\": 2}\n","MODEL_CHECKPOINT = \"neuralmind/bert-base-portuguese-cased\"\n","\n","OUTPUT_DIR = f\"models/{MODEL_NAME}-finetuned-{TASK}\"\n","\n","TOKENIZER = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, use_fast=True)\n","MODEL = AutoModelForSequenceClassification.from_pretrained(\n","    MODEL_CHECKPOINT, num_labels=NUM_LABELS, id2label=ID2LABEL, label2id=LABEL2ID\n",")"],"metadata":{"id":"6ahZJ6dnedml","executionInfo":{"status":"ok","timestamp":1714684541150,"user_tz":180,"elapsed":3732,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7fff9cf9-5f06-4a9e-d986-0016aa196bf8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["def tokenize_function(examples: DatasetDict):\n","    return TOKENIZER(\n","        examples[\"text\"], padding=\"max_length\", max_length=MAX_LENGTH, truncation=True\n","    )"],"metadata":{"id":"z88KE4WRUnlY","executionInfo":{"status":"ok","timestamp":1714684541151,"user_tz":180,"elapsed":12,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def compute_metrics(predictions, references):\n","\n","    predictions = predictions.detach().cpu().numpy().tolist()\n","    references = references.detach().cpu().numpy().tolist()\n","\n","    accuracy = accuracy_score(references, predictions)\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        references, predictions, average=\"macro\", zero_division=0\n","    )\n","\n","    return {\n","        f\"accuracy\": accuracy,\n","        f\"f1\": f1,\n","        f\"precision\": precision,\n","        f\"recall\": recall,\n","    }\n"],"metadata":{"id":"jd9QK-yYUttE","executionInfo":{"status":"ok","timestamp":1714684541152,"user_tz":180,"elapsed":13,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def training_step(train_dataloader, optimizer, lr_scheduler, progress_bar, epoch) -> dict:\n","\n","    prefix = \"train\"\n","    train_metrics = {\n","        \"mode\": [],\n","        \"step\": [],\n","        \"epoch\": [],\n","        \"loss\": [],\n","        \"accuracy\": [],\n","        \"f1\": [],\n","        \"precision\": [],\n","        \"recall\": [],\n","    }\n","\n","    for idx, batch in enumerate(train_dataloader):\n","\n","        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n","        outputs = MODEL(**batch)\n","        loss = outputs.loss\n","        loss.backward()\n","\n","        # \"Logging\" training metrics\n","        logits = outputs.logits\n","        predictions = torch.argmax(logits, dim=-1)\n","        references = batch[\"labels\"]\n","\n","        metrics = compute_metrics(predictions, references)\n","\n","        train_metrics[\"mode\"].append(prefix)\n","        train_metrics[\"step\"].append(idx)\n","        train_metrics[\"epoch\"].append(epoch)\n","        train_metrics[\"loss\"].append(loss.detach().cpu().numpy().tolist())\n","        train_metrics[\"accuracy\"].append(metrics[\"accuracy\"])\n","        train_metrics[\"f1\"].append(metrics[\"f1\"])\n","        train_metrics[\"precision\"].append(metrics[\"precision\"])\n","        train_metrics[\"recall\"].append(metrics[\"recall\"])\n","\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)\n","\n","    return train_metrics"],"metadata":{"id":"SrAGtCH5UwFI","executionInfo":{"status":"ok","timestamp":1714684541152,"user_tz":180,"elapsed":12,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def evaluation_step(eval_dataloader: DataLoader, epoch: int) -> dict:\n","\n","    prefix = \"eval\"\n","    eval_metrics = {\n","        \"mode\": [],\n","        \"step\": [],\n","        \"epoch\": [],\n","        \"loss\": [],\n","        \"accuracy\": [],\n","        \"f1\": [],\n","        \"precision\": [],\n","        \"recall\": [],\n","    }\n","\n","    for idx, batch in enumerate(eval_dataloader):\n","        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n","        with torch.no_grad():\n","            outputs = MODEL(**batch)\n","\n","        loss = outputs.loss\n","        logits = outputs.logits\n","        predictions = torch.argmax(logits, dim=-1)\n","        references = batch[\"labels\"]\n","\n","        # \"Logging\" evaluation metrics\n","        metrics = compute_metrics(predictions, references)\n","\n","        eval_metrics[\"mode\"].append(prefix)\n","        eval_metrics[\"step\"].append(idx)\n","        eval_metrics[\"epoch\"].append(epoch)\n","        eval_metrics[\"loss\"].append(loss.detach().cpu().numpy().tolist())\n","        eval_metrics[\"accuracy\"].append(metrics[\"accuracy\"])\n","        eval_metrics[\"f1\"].append(metrics[\"f1\"])\n","        eval_metrics[\"precision\"].append(metrics[\"precision\"])\n","        eval_metrics[\"recall\"].append(metrics[\"recall\"])\n","\n","    return eval_metrics"],"metadata":{"id":"mQ8CZCuvUyV_","executionInfo":{"status":"ok","timestamp":1714684541152,"user_tz":180,"elapsed":11,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def load_data(data_path):\n","\n","    ds = load_from_disk(data_path)\n","    ds = ds.map(tokenize_function, batched=True)\n","    ds = ds.remove_columns([\"text\"])\n","    ds.set_format(\"torch\")\n","\n","    train_dataloader = DataLoader(ds[\"train\"], shuffle=True, batch_size=BATCH_SIZE)\n","    eval_dataloader = DataLoader(ds[\"dev\"], shuffle=False, batch_size=BATCH_SIZE)\n","\n","    return train_dataloader, eval_dataloader\n"],"metadata":{"id":"QnwsBsHREkzv","executionInfo":{"status":"ok","timestamp":1714684541152,"user_tz":180,"elapsed":11,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def train(lr, wd, num_epochs, data_path):\n","\n","    training_set, evaluate_set = load_data(data_path)\n","    optimizer = AdamW(MODEL.parameters(), lr=lr, weight_decay=wd)\n","    num_training_steps = num_epochs * len(training_set)\n","    lr_scheduler = get_scheduler(\n","        name=\"linear\",\n","        optimizer=optimizer,\n","        num_warmup_steps=0,\n","        num_training_steps=num_training_steps,\n","    )\n","\n","    progress_bar = tqdm(range(num_training_steps))\n","    best_model_metric = 0\n","    logging_df = None\n","\n","    MODEL.to(DEVICE)\n","    for epoch in range(num_epochs):\n","        MODEL.train()\n","        train_metrics = training_step(training_set, optimizer, lr_scheduler, progress_bar, epoch)\n","        train_metrics = pd.DataFrame(train_metrics)\n","        print(train_metrics)\n","\n","\n","        MODEL.eval()\n","        eval_metrics = evaluation_step(evaluate_set, epoch)\n","        eval_metrics = pd.DataFrame(eval_metrics)\n","        print(eval_metrics)\n","\n","        logging_df = pd.concat(\n","            [logging_df, train_metrics, eval_metrics], axis=0, ignore_index=True\n","        )\n","        logging_df.to_csv(f\"{OUTPUT_DIR}/training-log.csv\", index=False)\n","\n","\n","\n","        eval_f1_score = sum(eval_metrics[\"f1\"]) / len(eval_metrics[\"f1\"])\n","        if eval_f1_score > best_model_metric:\n","            best_model_metric = eval_f1_score\n","\n","            MODEL.save_pretrained(f\"{OUTPUT_DIR}/hugging-face-save\")\n","            torch.save(\n","                {\n","                    \"epoch\": epoch,\n","                    \"model_state_dict\": MODEL.state_dict(),\n","                    \"optimizer_state_dict\": optimizer.state_dict(),\n","                    \"loss\": train_metrics[\"loss\"],\n","                },\n","                f\"{OUTPUT_DIR}/pytorch-save\",\n","            )\n"],"metadata":{"id":"1HQcSG1bFCML","executionInfo":{"status":"ok","timestamp":1714684541153,"user_tz":180,"elapsed":12,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train(lr=5e-5,\n","      wd=0.01,\n","      num_epochs=5,\n","      data_path=\"/content/drive/MyDrive/sentiment-analysis/data/intermediate/without-emoticons\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2987af016de046f19f9d55cce51dc3ff","9ad3284136b64d2f8614e2a9a77ddf99","035a820859614a95983f715f1d2ac3b3","f0292a7bdc7f4248bae9a0c020df6194","72c0c677febe48e58afd8cc05be8bb77","6d6abc5ad2f6488994caae1ea3a576fd","395c347cd2724a6a84718d118f192ada","eb3b5bf7042d43b792ea0b06fcfe5cac","3c03900bf68f4f24b109e0b5a36c976a","cab01e20628a46dd9c51b6e669de727d","ebae17fa9af1446ba0f65ab56ecc1c82"]},"id":"vjHTPVvDFQX3","executionInfo":{"status":"ok","timestamp":1714715535315,"user_tz":180,"elapsed":12186414,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}},"outputId":"d132964a-4b63-4503-9053-b4c4911c7ee0"},"execution_count":11,"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2987af016de046f19f9d55cce51dc3ff","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/24630 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"output_type":"stream","name":"stdout","text":["       mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     train     0      0  1.124521  0.242188  0.223854   0.413375  0.353726\n","1     train     1      0  0.992461  0.593750  0.249589   0.199475  0.333333\n","2     train     2      0  0.910455  0.585938  0.246305   0.195312  0.333333\n","3     train     3      0  0.845725  0.625000  0.256410   0.208333  0.333333\n","4     train     4      0  0.847026  0.609375  0.252427   0.203125  0.333333\n","...     ...   ...    ...       ...       ...       ...        ...       ...\n","4921  train  4921      0  0.470691  0.750000  0.796500   0.826031  0.782517\n","4922  train  4922      0  0.421554  0.828125  0.838869   0.867305  0.816760\n","4923  train  4923      0  0.414202  0.843750  0.832423   0.854637  0.825785\n","4924  train  4924      0  0.434105  0.757812  0.830323   0.830787  0.829927\n","4925  train  4925      0  0.309498  0.839506  0.857955   0.867284  0.851378\n","\n","[4926 rows x 8 columns]\n","      mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     eval     0      0  0.327175  0.828125  0.848291   0.825573  0.876263\n","1     eval     1      0  0.460670  0.804688  0.830435   0.856438  0.810577\n","2     eval     2      0  0.383437  0.804688  0.817941   0.794562  0.845999\n","3     eval     3      0  0.408682  0.804688  0.790949   0.789872  0.792356\n","4     eval     4      0  0.383636  0.789062  0.852685   0.855291  0.862009\n","...    ...   ...    ...       ...       ...       ...        ...       ...\n","1051  eval  1051      0  0.360625  0.843750  0.878580   0.878580  0.878580\n","1052  eval  1052      0  0.418298  0.812500  0.832632   0.858333  0.813131\n","1053  eval  1053      0  0.321600  0.867188  0.872605   0.893519  0.856633\n","1054  eval  1054      0  0.420582  0.820312  0.814252   0.824753  0.808442\n","1055  eval  1055      0  0.435042  0.825397  0.832647   0.861514  0.814035\n","\n","[1056 rows x 8 columns]\n","       mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     train     0      1  0.280888  0.851562  0.889007   0.884591  0.895664\n","1     train     1      1  0.358431  0.820312  0.815447   0.776715  0.873170\n","2     train     2      1  0.342046  0.835938  0.877751   0.876941  0.878647\n","3     train     3      1  0.335305  0.835938  0.846218   0.845246  0.858080\n","4     train     4      1  0.326256  0.843750  0.856500   0.880287  0.836400\n","...     ...   ...    ...       ...       ...       ...        ...       ...\n","4921  train  4921      1  0.281089  0.843750  0.875409   0.880991  0.871421\n","4922  train  4922      1  0.231942  0.929688  0.927353   0.938947  0.917702\n","4923  train  4923      1  0.363421  0.851562  0.878894   0.887566  0.872903\n","4924  train  4924      1  0.319929  0.867188  0.881766   0.901154  0.865195\n","4925  train  4925      1  0.357934  0.851852  0.884615   0.895062  0.878095\n","\n","[4926 rows x 8 columns]\n","      mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     eval     0      1  0.235374  0.898438  0.878600   0.857831  0.914724\n","1     eval     1      1  0.302677  0.859375  0.867565   0.899903  0.841279\n","2     eval     2      1  0.281271  0.859375  0.875383   0.895934  0.863275\n","3     eval     3      1  0.291403  0.890625  0.915035   0.928526  0.908097\n","4     eval     4      1  0.300247  0.875000  0.879046   0.866865  0.901735\n","...    ...   ...    ...       ...       ...       ...        ...       ...\n","1051  eval  1051      1  0.264359  0.882812  0.906646   0.914530  0.901411\n","1052  eval  1052      1  0.351872  0.835938  0.843289   0.845058  0.857420\n","1053  eval  1053      1  0.286271  0.890625  0.905649   0.937908  0.892259\n","1054  eval  1054      1  0.309284  0.875000  0.878548   0.921620  0.848485\n","1055  eval  1055      1  0.335261  0.873016  0.863252   0.903794  0.832456\n","\n","[1056 rows x 8 columns]\n","       mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     train     0      2  0.267386  0.882812  0.899992   0.916667  0.889522\n","1     train     1      2  0.288970  0.882812  0.865102   0.835758  0.907127\n","2     train     2      2  0.208322  0.929688  0.941818   0.959188  0.930740\n","3     train     3      2  0.396445  0.812500  0.835361   0.817100  0.857551\n","4     train     4      2  0.245106  0.914062  0.904944   0.883218  0.931805\n","...     ...   ...    ...       ...       ...       ...        ...       ...\n","4921  train  4921      2  0.198173  0.898438  0.922938   0.930894  0.917467\n","4922  train  4922      2  0.275349  0.890625  0.912500   0.915796  0.909643\n","4923  train  4923      2  0.313164  0.898438  0.896786   0.924039  0.874650\n","4924  train  4924      2  0.312412  0.890625  0.911465   0.924452  0.902635\n","4925  train  4925      2  0.250094  0.876543  0.901235   0.905240  0.898268\n","\n","[4926 rows x 8 columns]\n","      mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     eval     0      2  0.225397  0.898438  0.923354   0.922174  0.924631\n","1     eval     1      2  0.320005  0.867188  0.876110   0.901370  0.857107\n","2     eval     2      2  0.287169  0.890625  0.906513   0.915787  0.899311\n","3     eval     3      2  0.286373  0.890625  0.916617   0.921767  0.913022\n","4     eval     4      2  0.292077  0.890625  0.921370   0.921370  0.921370\n","...    ...   ...    ...       ...       ...       ...        ...       ...\n","1051  eval  1051      2  0.258301  0.906250  0.928353   0.925121  0.933167\n","1052  eval  1052      2  0.373529  0.835938  0.849812   0.833377  0.870629\n","1053  eval  1053      2  0.280623  0.906250  0.912090   0.914225  0.914873\n","1054  eval  1054      2  0.222337  0.914062  0.911616   0.942480  0.886364\n","1055  eval  1055      2  0.320720  0.873016  0.900472   0.896465  0.906140\n","\n","[1056 rows x 8 columns]\n","       mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     train     0      3  0.213650  0.898438  0.903492   0.889753  0.920740\n","1     train     1      3  0.222138  0.906250  0.928488   0.934959  0.923647\n","2     train     2      3  0.225905  0.906250  0.935501   0.937662  0.934600\n","3     train     3      3  0.245207  0.921875  0.944144   0.948465  0.941239\n","4     train     4      3  0.210745  0.921875  0.941546   0.937690  0.946970\n","...     ...   ...    ...       ...       ...       ...        ...       ...\n","4921  train  4921      3  0.174038  0.953125  0.963532   0.963532  0.963532\n","4922  train  4922      3  0.241612  0.890625  0.892972   0.865926  0.927635\n","4923  train  4923      3  0.188795  0.921875  0.934379   0.934379  0.934379\n","4924  train  4924      3  0.257017  0.890625  0.894178   0.899898  0.889133\n","4925  train  4925      3  0.159960  0.925926  0.940392   0.954061  0.931469\n","\n","[4926 rows x 8 columns]\n","      mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     eval     0      3  0.228091  0.890625  0.916201   0.919048  0.913753\n","1     eval     1      3  0.374497  0.835938  0.853273   0.878904  0.833842\n","2     eval     2      3  0.314456  0.859375  0.875383   0.895934  0.863275\n","3     eval     3      3  0.307978  0.882812  0.910263   0.917027  0.905930\n","4     eval     4      3  0.322760  0.906250  0.932157   0.934167  0.930502\n","...    ...   ...    ...       ...       ...       ...        ...       ...\n","1051  eval  1051      3  0.250170  0.898438  0.920713   0.921957  0.919572\n","1052  eval  1052      3  0.387343  0.835938  0.845677   0.878049  0.819347\n","1053  eval  1053      3  0.296297  0.898438  0.915401   0.929762  0.906936\n","1054  eval  1054      3  0.204274  0.914062  0.911616   0.942480  0.886364\n","1055  eval  1055      3  0.348114  0.873016  0.868360   0.897215  0.848246\n","\n","[1056 rows x 8 columns]\n","       mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     train     0      4  0.194558  0.929688  0.946899   0.950957  0.943748\n","1     train     1      4  0.278580  0.898438  0.922613   0.929792  0.917905\n","2     train     2      4  0.125745  0.976562  0.981699   0.987179  0.977273\n","3     train     3      4  0.148537  0.953125  0.964928   0.967641  0.962622\n","4     train     4      4  0.206561  0.906250  0.920054   0.929038  0.913158\n","...     ...   ...    ...       ...       ...       ...        ...       ...\n","4921  train  4921      4  0.115735  0.953125  0.955556   0.969979  0.944129\n","4922  train  4922      4  0.128241  0.937500  0.943352   0.949223  0.938131\n","4923  train  4923      4  0.074824  0.976562  0.978901   0.975967  0.982008\n","4924  train  4924      4  0.171407  0.929688  0.937472   0.939988  0.935107\n","4925  train  4925      4  0.168598  0.925926  0.935315   0.935315  0.935315\n","\n","[4926 rows x 8 columns]\n","      mode  step  epoch      loss  accuracy        f1  precision    recall\n","0     eval     0      4  0.258099  0.890625  0.916201   0.919048  0.913753\n","1     eval     1      4  0.390738  0.835938  0.853273   0.878904  0.833842\n","2     eval     2      4  0.349982  0.875000  0.891266   0.905944  0.881293\n","3     eval     3      4  0.361355  0.882812  0.910263   0.917027  0.905930\n","4     eval     4      4  0.336695  0.898438  0.926750   0.927652  0.925936\n","...    ...   ...    ...       ...       ...       ...        ...       ...\n","1051  eval  1051      4  0.285503  0.898438  0.919937   0.924262  0.916563\n","1052  eval  1052      4  0.423985  0.851562  0.884357   0.891978  0.879176\n","1053  eval  1053      4  0.338257  0.882812  0.892018   0.895901  0.894434\n","1054  eval  1054      4  0.225639  0.906250  0.905182   0.938214  0.878788\n","1055  eval  1055      4  0.437870  0.841270  0.840669   0.873932  0.814912\n","\n","[1056 rows x 8 columns]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_aFjIaaEdhiY","executionInfo":{"status":"ok","timestamp":1714715535316,"user_tz":180,"elapsed":2,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8bqx90aa5kay","executionInfo":{"status":"ok","timestamp":1714715540616,"user_tz":180,"elapsed":1381,"user":{"displayName":"Ivan Carlos Alcântara de Oliveira","userId":"12384813331613440241"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eXjyfmJwQ2sR"},"execution_count":null,"outputs":[]}]}