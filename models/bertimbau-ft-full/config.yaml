seed_everything: 42
model:
  n_classes: 3
  learning_rate: 0.001
  model_checkpoint: neuralmind/bert-base-portuguese-cased
  id2label: {0: "Neutro", 1: "Positivo", 2: "Negativo"}
  label2id: {"Neutro": 0, "Positivo": 1, "Negativo": 2}
  # Computed on the training set with sklearn.utils.class_weight.compute_class_weight
  class_weights:
    - 5.63462742
    - 1.01479668
    - 0.54433414
  train_last_n_layers: "full"
data:
  raw_data_dir: data/raw/
  processed_data_dir: data/processed/
  batch_size: 128
  num_workers: 2
  model_checkpoint: neuralmind/bert-base-portuguese-cased
  max_length: 128
  cleaning_steps:
    - from_unicode_to_ascii
    - remove_user_from_tweet
    - remove_urls
    - remove_non_word_chars
    - remove_repeated_chars
    - remove_trailing_whitespace
trainer:
  fast_dev_run: false
  max_epochs: 3
  min_epochs: 1
  profiler: advanced
  logger:
    - class_path: lightning.pytorch.loggers.CSVLogger
      init_args:
        save_dir: models/bertimbau-ft-full/
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: models/bertimbau-ft-full/checkpoint/
        filename: "bertimbau-{epoch}-{val_f1:.2f}"
        monitor: val_f1
        every_n_train_steps: 100